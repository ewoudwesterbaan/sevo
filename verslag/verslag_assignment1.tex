\documentclass[a4paper]{article}

\usepackage{xcolor}
\usepackage{fancyheadings}
\usepackage{listings}
\usepackage{graphicx}
\usepackage[utf8]{inputenc}
\usepackage{multirow}
\lstset{frameround=fttt,numbers=left,breaklines=true, extendedchars=true}

\newcommand{\todo}[1]{\textcolor{red}{[#1]}}
\lhead{Open Universiteit}
\chead{IM0202, Software evolution}
\rhead{Assignment 1}

\begin{document}
\pagestyle{fancy}

\section*{Studentgegevens}
\begin{description}
	\item [Cursuscode] IM0202
	\item [Naam] Ewoud Westerbaan
	\item [Studentnummer] 852069942
	\item [Naam] Martin de Boer
	\item [Studentnummer] 837372832
\end{description}

\section*{Samenwerking}
Bij de start van het practicum zijn we parallel aan elkaar aan onze "eigen" modules begonnen: Main.rsc, Volume.rsc en Duplicates.rsc door Ewoud, en UnitSize.rsc, Complexity.rsc, Aggregate.rsc en Rate.rsc door Martin. Gaandeweg het project zijn we intensiever gaan samenwerken: Ewoud heeft Utils.rsc gemaakt waarin code is opgenomen die door meerdere modules wordt aangeroepen, en Martin heeft een opzet gemaakt voor de unittesten. Tijdens het bugfixen hebben we ook elkaars modules verder verbeterd. De diverse modules worden hieronder kort toegelicht.

\section{Structuur}
De volgende modules zijn in het Rascal project opgenomen:
\begin{description}
\item[Main.rsc] De hoofdmodule. Van hieruit worden de andere modules aangeroepen en wordt de uitvoer gegenereerd.
\item[metrics::Volume.rsc] Berekent het volume (LOC) van de SmallSQL aplicatie.
\item[metrics::UnitSize.rsc] Berekent het aantal regels code per unit (methode/constructor). Er zijn verschillen in de som van de unitsize ten opzicht van het volume. Wij beschouwen het volume als alle regels code in een java file, zonder commentaar en zonder de lege ruimtes, zoals ook in \cite{A}, maar inclusief velddefinities, constantendefinities, import statements e.d. De som van de coderegels in units is de som van de inhoud (!) van de methodes en constructoren.
\item[metrics::Complexity.rsc] Bepaalt de complexiteit per unit. We gaan er vanuit dat de standaard complexiteitsmaat de waarde 1 heeft, en dat er voor een aantal taalconstructies reden is om deze met 1 te verhogen. Deze taalconstructies blijken duidelijk uit listing 1.
\item[metrics::Duplicate.rsc] Zoekt de dubbele code in de sources van SmallSQL
\item[metrics::Aggregate.rsc] Aggregeert de gegevens van de bovenstaande modules, en bepaalt de percentages t.b.v. de rating. Hierbij wordt rekening gehouden met de som van de unit sizes (en niet het totale volume, zie boven).
\item[metrics::Rate.rsc] Bepaalt de rating van SmallSQL per onderdeel (unit size, complexiteit en duplicaten).
\item[utils::Utils] Bevat een aantal utility functies.
\end{description}
\section{Aannames}
\subsection{Duplicaten}
In onze oplossing vergelijken we de content van methodes en constructoren met elkaar, maar dit gebeurt in één richting. Als methode A wordt vergeleken met methode B, wordt methode B niet meer vergeleken met methode A. Stel dat het aantal opeenvolgende regels dat identiek is, 6 is. Dan is de duplicatiewaarde over de oplossing dus 6 / 12, dus 50\%. Als we dan drie methodes gebruiken, dan wordt methode A met methode B vergeleken, methode A met methode C én methode B en methode C. Het aantal duplicate regels is dan 18, wat gelijk is aan het totaal van aantal regels. In figuur \ref{fig:DuplicatenDetectie} hebben we dit doorgetrokken. op de x as staan het aantal methodes dat dezelfde code bevat. De blauwe lijn geeft het totaal aantal regels code in de oplossing aan, en de rode lijn het aantal gedetecteerde duplicate regels. Het aantal duplicate regels loopt dus exponentieel.
\begin{figure}[htbp]
\caption{Oplopen van detectieregels bij meerdere methodes}
\centering
\includegraphics[width=0.8 \textwidth]{DuplicatenDetectie.png}
\label{fig:DuplicatenDetectie}
\end{figure}
Onze aanname is dat het aantal duplicate regels het totaal van regels is dat meerdere keren in de applicatie voorkomt. Dit hebben wij geimplementeerd door de set van unitparen te verdelen over sets gegeven het aantal duplicate regels. Van deze set maken wij een set van 2-tuples waarbij we de locatie en het startnummer binnen de content concateneren. Vervolgens beschouwen we deze nieuwe relatie als een graaf waarbij we het aantal units vermenigvuldigen met het aantal duplicate regels.

Ter verduidelijking: laten we aannemen dat we 4 gelijke methodes hebben van 6 regels code. Als we voorheen de duplicatie berekende, kregen we 6 onderlinge verbindingen maal 6 regels duplicate code is 36 regels (van de 24 in totaal). Met de bovenbeschreven methode krijgen we dan een groep van 4 elementen. Dit maal 6 regels duplicate code levert 24 op.

Op deze manier zal ook een enkele duplicaat (dus 2 units dat dezelfde code bevatten) geen 50\% score opleveren, maar 100\%. Dat zagen we ook terug in het draaien met de verschillende vormen over het testobject (SmallSQL); voorheen hadden we een score van 4,5\%, maar met de laatste vorm een score van ongeveer 12\%.

\subsection{Complexity}
De complexiteitsmaat heeft betrekking op het aantal paden die in
een unit (methode of constructor) kan worden bewandeld. Dit zegt
iets over de testbaarheid van zo'n unit. We gaan er vanuit dat
de standaard complexiteitsmaat de waarde 1 heeft, en dat er voor
een aantal taaconstructies reden is om deze met 1 te verhogen.
Deze taalconstructies blijken duidelijk uit de onderstaande
code:

\begin{lstlisting}[caption={Taalsconstructies die de
complexiteit verhogen},label={lst:complexity},escapechar=|,
frame = single]
int complexity = 1;
visit(stat) {
  case \case(_) : complexity += 1;
  case \do(_, _) : complexity += 1;
  case \if(_, _) : complexity += 1;
  case \catch(_,_): complexity += 1;
  case \while(_, _) : complexity += 1;
  case \if(_, _, _) : complexity += 1;
  case \for(_, _, _) : complexity += 1;
  case infix(_,"&&",_) : complexity += 1;
  case infix(_,"||",_) : complexity += 1;    
  case \for(_, _, _, _) : complexity += 1;
  case \foreach(_, _, _) : complexity += 1;
  case \conditional(_,_,_): complexity += 1;
}
\end{lstlisting}

De \texttt{if}-constructies spreken voor zich: de conditie kan
waar zijn of niet. Er zijn dus twee mogelijkheden, waarmee het
aantal mogelijke paden met 1 wordt uitgebreid. Ditzelfde geldt
voor de \texttt{conditional} in Java (feitelijk een alternatieve
manier van het schrijven van een if-constructie, bijv.:
\texttt{b == true ? x : y;}). De \texttt{do}, \texttt{while},
\texttt{for}, en \texttt{foreach} be\"invloeden de complexiteit
op een vergelijkbare manier. In het \texttt{switch}-statement,
is iedere \texttt{case} te beschouwen als een
\texttt{if}-statement, en dus verhogen we voor iedere
\texttt{case} de complexiteitsmaat met 1.
De \texttt{default}-tak voegt wel een extra stap, maar geen
extra pad aan de sequentie van statements toe, en heeft dus geen
invoed op de complexiteitsmaat.
Het optreden van een exception kan worden afgehandeld in een
\texttt{catch}-blok. Ieder \texttt{catch}-blok voegt een nieuw
pad aan de control-flow van het programma toe, zodat ook dit de
complexiteit verhoogd.
Tenslotte is er de infix-notatie (AND, of OR-variant) die
invloed heeft op het aantal paden. We verhogen hiervoor de de
complexiteitsmaat wederom met 1, omdat het al dan niet
\texttt{true} zijn van de linker-conditie bepaald of de tweede
conditie wordt bepaald.

\section{Betrouwbaarheid}
De betrouwbaaheid en de juistheid van de oplossing kunnen we waarborgen door het gebruik van unittests. 
We hebben meerdere `dummy'-projecten gemaakt die dienen als referentieproject bij het draaien van deze tests. 
Door dat we zelf deze projecten maken, welke klein en overzichtelijk zijn, kunnen we vrij specifiek meten, testen en de juistheid valideren van de opgeleverde code. In Listing \ref{lst:testoutput} is de output weergegeven van onze unittests.
\begin{lstlisting}[caption={Unit test output},label={lst:testoutput},frame = single]
Running tests for tests::metrics::VolumeTest
Test report for tests::metrics::VolumeTest                                                
        all 3/3 tests succeeded
Running tests for tests::metrics::AggregateTest
Test report for tests::metrics::AggregateTest                                             
        all 4/4 tests succeeded
Running tests for tests::utils::TestUtilsTest
Test failed. Msg: ** No worries! This test should fail **. Expected = 1, actual = 2       
Test failed. Msg: ** No worries! This test should fail **. Expected = blabla, actual = bla
Test report for tests::utils::TestUtilsTest                                 
        all 5/5 tests succeeded
Running tests for tests::utils::UtilsTest
Test report for tests::utils::UtilsTest                                                     
        all 18/18 tests succeeded
Running tests for tests::metrics::UnitSizeTest
Test report for tests::metrics::UnitSizeTest                                              
        all 2/2 tests succeeded
Running tests for tests::metrics::DuplicationTest
Test report for tests::metrics::DuplicationTest                                             
        all 13/13 tests succeeded
Running tests for tests::metrics::ComplexityTest
Test report for tests::metrics::ComplexityTest                                            
        all 2/2 tests succeeded
Running tests for tests::metrics::RateTest
Test report for tests::metrics::RateTest                                                    
        all 11/11 tests succeeded
\end{lstlisting}
\section{Resultaten en interpretatie}
In Listing \ref{lst:output} is de output van het geschreven programma te zien over SmallSQL. 

\begin{lstlisting}[caption={Programma output SmallSQL},label={lst:output},frame = single]
Volume berekenen ...
Berekend volume: 
- totaal aantal regels (incl. lege regels): 35271
- commentaarregels: 4102
- coderegels: 22192

Unit size berekenen ...
Aantal gevonden units (methodes en constructoren): 2494
Som van de aantallen regels per methode/constructor:
- totaal aantal regels (incl lege regels binnen de units): 22730
- commentaarregels: 628
- coderegels: 16401

Berekenen cyclomatische complexiteit ...

Aggregeren gegevens (unit size and complexity) ...
- Categorie Simple (Without much risk): 67%
- Categorie Moderate (With moderate risk): 10%
- Categorie Untestable (Untestable, very high risk): 7%
- Categorie Complex (Complex, with high risk): 14%
- Rank op basis van aggregatie: --

Berekenen duplicatie ...
size of pairs to check: 203203
- Aantal duplicaties: 188
- Aantal regels gedupliceerd: 1976
- Duplicatepercentage: 12.04804585%

Programma beeindigd
\end{lstlisting}
Als we de output van \ref{lst:output} nemen en deze tegen de referentie tabellen aanhouden als in \cite{A}, kunnen we een soortgelijk resultatentabel invullen. Omdat wij unittesting niet gemeten hebben, laten we deze buiten beschouwing.

Voor de interpretatie van de unitsizes zijn door \cite{A} geen strikte waardes gegeven, daarom dienen wij hier zelf een methode voor te bedenken.
Wij kiezen ervoor om de verdeling aan te houden als in \cite{B}, zodat we de uitkomst kunnen vergelijken met de gemiddelde.

Als we de verhouding in \cite{B} aannemen, komen we op een verdeling als in Tabel \ref{tbl:UnitSizeClassificatie}.

\begin{table}[h]
\caption{Unitsize classificatie}
\label{tbl:UnitSizeClassificatie}
\begin{tabular}{|l|l|}
\hline
Unitsize         & Classificatie      \\ \hline
0-15             & small units        \\
16-50            & medium sized units \\
51-100           & large units        \\
101-150          & very large units   \\
\textgreater{}250& insane             \\ \hline
\end{tabular}
\end{table}

Wij vergelijken de uitkomst van het programma met de waardes uit \cite{B}. De applicatie dat onderzocht wordt kan dan boven (+), onder (-) of gelijk (o) scoren. Ter referentie hebben we de grafiek uit \cite{B} toegevoegd (zie Figuur \ref{fig:RefVerdeling}).
\begin{figure}[htbp]
%\caption{Oplopen van detectieregels bij meerdere methodes}
\centering
\includegraphics[width=0.8 \textwidth]{Capture.png}
\label{fig:RefVerdeling}
\end{figure}

Wel willen wij hierbij de opmerking plaatsen dat de verdeling ons inziens te grof is. Wij zijn van mening dat de verhoudingen beter kunnen. Nader onderzoek zal plaats moeten vinden om een betere verdeling te maken. Toch kiezen wij ervoor om te refereren met \cite{B}, zodat we de uitkomsten ergens mee kunnen vergelijken. De unitsize uit het doorgerekende project (SmallSQL) heeft 28\% 1-15, 35\% 16-50, 14\% 51-100, 8\% 101-250 en 3\% \textgreater{}250.
Als we dit vergelijken met Figuur \ref{fig:RefVerdeling}, scoort SmallSQL op het oog gelijk en krijgt daarom we waarde 0.


Als we alle waardes in de tabel zetten zoals in \cite{A}, komen we uit op Tabel \ref{tbl:ResultaatSmallSQL}. De laatste kolom hiervan lichten we toe.
\begin{description}
\item[Analysability] Analysability is afhankleijk van volume (++), complexity per unit (- - ) en unit size (0). Bij elkaar komt vinden wij dat dit een neutrale score oplevert van 0.
\item[Changeability] Omdat de complexity per unit zeer hoog is, en de hoeveelheid duplicatie ook vrij hoog is, geven we changeability de score -.
\item[Stability] We hebben de waarde van de unit testing niet gemeten. Hierdoor kunnen we niets zeggen over de stability en krijgt deze de neutrale waarde 0.
\item[Testability] Omdat we unit testing niet hebben gemeten, is de testability volledig afhankelijk van de complexity per unit. Deze is voor SmallSQL zeer hoog en daarom geven we testability de gelijke waarde als complexity per unit: - -.
\end{description}
\begin{table}[h]
\caption{Resultaat SmallSQL}
\label{tbl:ResultaatSmallSQL}
\begin{tabular}{llllllll}
                          &                                                      &                                    & \multicolumn{5}{l}{source code properties}                                                                                                                           \\ \cline{4-7}
                          &                                                      & \multicolumn{1}{l|}{}              & \multicolumn{1}{c|}{\rotatebox[origin=c]{90}{volume}} & \multicolumn{1}{c|}{\rotatebox[origin=c]{90}{ complexity per unit }} & \multicolumn{1}{c|}{\rotatebox[origin=c]{90}{duplication}} & \multicolumn{1}{c|}{\rotatebox[origin=c]{90}{unit size}} &                         \\ \cline{4-7}
                          &                                                      & \multicolumn{1}{l|}{}              & \multicolumn{1}{c|}{++}       & \multicolumn{1}{c|}{- -}                    & \multicolumn{1}{c|}{-}            & \multicolumn{1}{l|}{0}          &                         \\ \cline{3-8} 
\multirow{4}{*}{\rotatebox[origin=c]{90}{ISO 9128}} & \multicolumn{1}{l|}{\multirow{4}{*}{\rotatebox[origin=c]{90}{maintainablity}}} & \multicolumn{1}{l|}{analysability} & \multicolumn{1}{c|}{X}      & \multicolumn{1}{l|}{}                    & \multicolumn{1}{c|}{X}           & \multicolumn{1}{c|}{X}         & \multicolumn{1}{c|}{0} \\ \cline{3-8} 
                          & \multicolumn{1}{l|}{}                                & \multicolumn{1}{l|}{changeability} & \multicolumn{1}{l|}{}       & \multicolumn{1}{c|}{X}                   & \multicolumn{1}{c|}{X}           & \multicolumn{1}{l|}{}          & \multicolumn{1}{c|}{- -} \\ \cline{3-8} 
                          & \multicolumn{1}{l|}{}                                & \multicolumn{1}{l|}{stability}     & \multicolumn{1}{l|}{}       & \multicolumn{1}{c|}{}                    & \multicolumn{1}{l|}{}            & \multicolumn{1}{l|}{}          & \multicolumn{1}{c|}{0} \\ \cline{3-8} 
                          & \multicolumn{1}{l|}{}                                & \multicolumn{1}{l|}{testability}   & \multicolumn{1}{l|}{}       & \multicolumn{1}{c|}{X}                   & \multicolumn{1}{l|}{}            & \multicolumn{1}{l|}{}          & \multicolumn{1}{c|}{- -} \\ \cline{3-8} 
\end{tabular}
\end{table}

\bibliographystyle{abbrv}
\bibliography{verslag_assignment1}

\end{document}
